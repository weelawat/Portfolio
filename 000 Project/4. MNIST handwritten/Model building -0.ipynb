{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library & Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: dlopen(/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so, 2): no suitable image found.  Did find:\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashtable\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_hashtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtslib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tslib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/pandas/_libs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from pandas._libs.tslibs import (\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so, 2): no suitable image found.  Did find:\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2ceacad6900f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# hack but overkill to use re\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot import name \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;34mf\"C extension: {module} not built. If you want to import \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: C extension: dlopen(/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so, 2): no suitable image found.  Did find:\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture\n\t/Users/wee/NaTF/lib/python3.8/site-packages/pandas/_libs/interval.cpython-38-darwin.so: mach-o, but wrong architecture not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACcCAYAAACp45OYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAALLklEQVR4nO2de4xU9RXHP4d1cXlaEEFEER88XG3Vig9aFVqLgo01JkUlVSliaGJVfBa1NrXaNmpMtbaQ1lTeLaaRRo2lWKDQVMUKVCkgriDy2IIidFVApLtw+sfchTmXfQy/mbkzO3M+yWTu9859nNn9zu+e+7u/e66oKo5zuLQrdABO28SN4wThxnGCcOM4QbhxnCDcOE4QbpxWEJHFInJT0usWO2VjHBHZICLfKHQcLSEid4jIByLyiYhMEZEjCx1Tc5SNcYodEbkMuBe4BOgHnAz8pJAxtUTZG0dEuonISyLykYjURdPHxxY7RUTeiFqCF0Ske9r6F4jIayLysYisEJFhgaGMAZ5R1dWqWgc8DHw3cFt5p+yNQ+pvMBU4EegL7AF+HVvmBuBG4DigAXgKQET6AH8Gfgp0B+4G5ojIMfGdiEjfyFx9m4njdGBFml4B9BKRowO/V14pe+Oo6g5VnaOqn6nqTuBnwNDYYjNVdZWq7gZ+BFwtIhXAdcBcVZ2rqvtVdT6wDLi8if1sUtUvqOqmZkLpDHySphunu2Tx9fLGEYUOoNCISEfgCWAE0C2a3UVEKlR1X6Q3p62yEagEepBqpUaJyBVpn1cCiwJC2QV0TdON0zsDtpV3yr7FAe4CBgLnq2pX4OJovqQtc0LadF+gHthOylAzo5ak8dVJVR8JiGM1cGaaPhP4UFV3BGwr75SbcSpFpCrtdQSpQ8Ee4OMo6f1xE+tdJyLVUev0EPBc1BrNAq4QkctEpCLa5rAmkutMmAGMi/bTDXgAmBbyJZOg3Iwzl5RJGl8PAk8CHUi1IK8D85pYbyapf+IHQBVwG4CqbgauBO4HPiLVAt1DE3/XKDne1VxyrKrzgMdIHeY2Rq+mTFwUiA/kckIotxbHyRFuHCcIN44TRFbGEZERIlIjIutE5N5cBeUUP8HJcdRz+i4wHKgFlgKjVfXt3IXnFCvZ9ByfB6xT1fUAIvIsqVPTZo3TXo7UKjplsUsnaXZSt11VD7n2lo1x+mC74muB81taoYpOnC+XZLFLJ2kW6HMbm5qfjXGkiXmHHPdEZDwwHqCKjlnszikmskmOa7HXcI4HtsQXUtWnVXWwqg6upGgHtDmHSTbGWQr0F5GTRKQ9cC3wYm7Ccoqd4EOVqjaIyC3Ay0AFMEVVV+csMqeoyWo8jqrOJXXh0CkzvOfYCcKN4wThxnGCcOM4QbhxnCDcOE4QbhwnCDeOE4Qbxwmi7O/kzAcNXz/H6K037zV6xZDpRp+5ZIzRx01qb3TFon/lMLrc4C2OE4QbxwnCD1U5YP/Qs41+aoqtknJqpf0z74+t/+aQqUbXDN5n9D39LsguwDzgLY4ThBvHCcKN4wThOU4g9ZcOPjD9g8kzzWcDKu3p9P5YVrO+vt7oT/bbsdhnx4Zm7x15rtEdFq202//889YDzjHe4jhBuHGcINw4ThCe4zRDRdeuRu++eJDRdzzxhwPTX+uwK7Z2y7/HaXVfMXrh5CFGv/rgU0bP/91vjK6edYvRJ09c0uL+8oG3OE4QbhwnCDeOE4TnOM1QO6OP0UvPnZSzbT/Uc6nR8zrbnGfshkuNnt5vgdFdqwtf+thbHCcIN44ThBvHCcJznIj4cM/ZZ9kxNe2w15/SGbvRVhlbtuA0o1eOs9tatKfK6J7L9hi9rs72GVX+3D5TpF1TJa0SxlscJ4hWjRM9G3KbiKxKm9ddROaLyNrovVtL23BKj0xanGmknuWUzr3AQlXtDyyMtFNGZFTnWET6AS+p6hmRrgGGqepWEekNLFbVga1tp6t012KpOhofJ/zk9MlGx8cJx/nWO1cdmK749m7z2X+/af8UO86wScmASZuNbthc2+K+XvrPcqO37rM50Y1jbjM6l7fTLNDnlqvq4Pj80Bynl6puBYjee2YTnNP2yPtZlZerLU1CW5wPo0MU0fu25hb0crWlSWiL8yKp52Q/Er2/kLOI8oScc7rR2++0eUJ8nPBye9cuf9tVbfSOZw+WeD66zo6HOWrW61bHYmloLdhW6FVhf4A7bv/M6J4hj5I9TDI5HZ8NLAEGikitiIwjZZjhIrKW1ENAQh5e6rRhWm1xVHV0Mx8Vx+mRUxC859gJomSvVbXraM/gGh771OjXB/3J6Pcb/mf0nfffZXS3f2wyumeng+cD9k7v5Dmvt33Ay4YE9uktjhOEG8cJwo3jBFGyOc6eobbf5uVBk5tZMsVNE+4wusvzti8m276XUsNbHCcIN44TRMkeqr708FtGt4v9RuLDPTs8/0a+QwqmUiqMro+NhKmQsEeAZ4O3OE4QbhwnCDeOE0TJ5DgfX29LhTzQ63Gj98dub1n+VztMoi+v5SewHFCv9qJGvDTcvDX2u/Qn/5XYvcVxgnDjOEG4cZwgSibHaehg9VHtbE6z5HM73PLkGVvs+nmJKjPiQ0DeefyM2BL29pjvrB9p9KAJ7xudxDAPb3GcINw4ThBuHCeIkslxWmPHvs5GN6zfUJhAODSnqXnki0a/c6Uti/KXz+wNNlsmnWp0lzo7BCQJvMVxgnDjOEG4cZwgyibHufvVUUYPiPWN5JN4SZVtsduP1wy2Oc0lK68xutOI9UZ3IfmcJo63OE4QbhwnCDeOE0Tp5DixEq7xMca/vHC20ZMYkLdQNj5kxwbNueEXRsdLqnz5jTFGH3fV2/kJLId4i+MEkUl9nBNEZJGIrBGR1SIyIZrvJWvLmExanAbgLlU9DbgA+L6IVOMla8uaTAorbQUaK4zuFJE1QB/gSmBYtNh0YDEwMS9RZkLs1qL4uNyhHeyjem6fZkvwnzLVLl/5wU6jPxx6jNHdrzlYYvbWvgvNZyM72j6iF3f3MvqGlbZsdI/fdqKtcVg5TlTv+Gzgn3jJ2rImY+OISGdgDnC7qn7a2vJp640XkWUisqyeva2v4LQJMjKOiFSSMs3vVbWxlFVGJWu9XG1p0mqOIyICPAOsUdX0Dok2VbK2SuxXXTPcPpL5lYvso4DW7j3W6LFHbch4XxO2XGT0vNfOMrr/hMJfa8qWTDoAvwpcD6wUkbeiefeTMswfo/K1m4BRTa/ulCKZnFW9wiH9sgfwkrVlivccO0GUzLWqXottbj7xe/Z60aPH2rL5cS6usuVqL6za0OLyb+49+Jsb/ffx5rMBY20/Tv8iGD+Ta7zFcYJw4zhBuHGcIEomx9n37ntGrx3Vz+jqW281+u2rf3VY2x8092ajB04++KifAW8mN365WPAWxwnCjeMEkdFTgHNFMT0F2MmMXD8F2Clz3DhOEG4cJwg3jhOEG8cJwo3jBOHGcYJw4zhBuHGcINw4ThBuHCcIN44ThBvHCcKN4wThxnGCSHQ8joh8BGwEegDbE9vx4eGxWU5U1WPiMxM1zoGdiixranBQMeCxZYYfqpwg3DhOEIUyztMF2m8meGwZUJAcx2n7+KHKCSJR44jICBGpEZF1IlLQ8rYiMkVEtonIqrR5RVG7uS3Ulk7MOCJSAUwCRgLVwOioXnKhmAaMiM0rltrNxV9bWlUTeQFDgJfT9H3AfUntv5mY+gGr0nQN0Dua7g3UFDK+tLheAIYXU3xJHqr6AJvTdG00r5goutrNxVpbOknjNFVH0E/pWiC0tnQSJGmcWuCENH08sCXB/WdCRrWbkyCb2tJJkKRxlgL9ReQkEWkPXEuqVnIx0Vi7GQpYuzmD2tJQ6NrSCSd5lwPvAu8BPyxwwjmb1MNN6km1huOAo0mdrayN3rsXKLYLSR3G/w28Fb0uL5b4VNV7jp0wvOfYCcKN4wThxnGCcOM4QbhxnCDcOE4QbhwnCDeOE8T/Ad0J4+ZjgzAiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(x_train[i][:, :])\n",
    "    plt.title(f\"Label: {y_train[i]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(\"float32\")/255\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "    \n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,014,634\n",
      "Trainable params: 1,012,650\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 1e-3),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range= 10,\n",
    "        zoom_range = 0.1,\n",
    "        width_shift_range = 0.1,\n",
    "        height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow(x_train, y_train, batch_size = 64)\n",
    "\n",
    "validation_generator = datagen.flow(x_test, y_test, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 1e-6)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('./best_model.hdf5',monitor = 'val_loss', mode = \"min\", verbose = 1, save_best_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Image transformations require SciPy. Install SciPy.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5d5ce2aa2513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enqueuer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m     super(KerasSequenceAdapter, self).__init__(\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Shuffle is handed in the _make_callable override.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             x = self.image_data_generator.apply_transform(\n\u001b[0m\u001b[1;32m    162\u001b[0m                 x.astype(self.dtype), params)\n\u001b[1;32m    163\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m         x = apply_affine_transform(x, transform_parameters.get('theta', 0),\n\u001b[0m\u001b[1;32m    864\u001b[0m                                    \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                                    \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NaTF/lib/python3.8/site-packages/keras_preprocessing/image/affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \"\"\"\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         raise ImportError('Image transformations require SciPy. '\n\u001b[0m\u001b[1;32m    282\u001b[0m                           'Install SciPy.')\n\u001b[1;32m    283\u001b[0m     \u001b[0mtransform_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Image transformations require SciPy. Install SciPy."
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = x_train.shape[0] // 64,\n",
    "    epochs = 50,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = x_test.shape[0] // 64,\n",
    "    callbacks = [learning_rate_reduction, model_checkpoint]\n",
    ")\n",
    "\n",
    "model.save(\"mnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = len(accuracy)\n",
    "\n",
    "plt.plot(range(epochs), accuracy, 'b', label='Training accuracy')\n",
    "plt.plot(range(epochs), val_accuracy, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(range(epochs), loss, 'b', label='Training Loss')\n",
    "plt.plot(range(epochs), val_loss, 'r', label='Training Loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
